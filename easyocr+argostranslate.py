import time
import mss
import numpy as np
import cv2
import easyocr
import argostranslate.package
import argostranslate.translate
import tkinter as tk
import threading
import keyboard
import pyautogui
from urllib.request import urlopen
# ========== å€åŸŸé¸æ“‡å™¨ ==========
def select_bbox():
    print("è«‹ç”¨æ»‘é¼ é»é¸å·¦ä¸Šè§’èˆ‡å³ä¸‹è§’")
    points = []

    def mouse_callback(event, x, y, flags, param):
        if event == cv2.EVENT_LBUTTONDOWN:
            points.append((x, y))
            print(f"é»æ“Š: {x}, {y}")
            if len(points) == 2:
                cv2.destroyAllWindows()

    screen = pyautogui.screenshot()
    screen_np = cv2.cvtColor(np.array(screen), cv2.COLOR_RGB2BGR)
    clone = screen_np.copy()

    cv2.namedWindow("é¸å–å€åŸŸ")
    cv2.setMouseCallback("é¸å–å€åŸŸ", mouse_callback)

    while len(points) < 2:
        disp = clone.copy()
        if len(points) == 1:
            cv2.rectangle(disp, points[0], pyautogui.position(), (0, 255, 0), 2)
        cv2.imshow("é¸å–å€åŸŸ", disp)
        if cv2.waitKey(10) == 27:  # ESC é›¢é–‹
            break

    if len(points) == 2:
        (x1, y1), (x2, y2) = points
        return {
            "left": min(x1, x2),
            "top": min(y1, y2),
            "width": abs(x2 - x1),
            "height": abs(y2 - y1)
        }
    else:
        return None

# ========== åˆå§‹åŒ– ==========
bbox = select_bbox()
if not bbox:
    print("æœªé¸æ“‡å€åŸŸï¼Œç¨‹å¼çµæŸ")
    exit()

prev_img = None
prev_text = ""
paused = False

reader = easyocr.Reader(['en'], gpu=False)
# argostranslate.translate.load_installed_languages()

def ensure_translation_installed(from_code="en", to_code="zh"):
    # è¼‰å…¥ç›®å‰å®‰è£çš„èªè¨€
    argostranslate.translate.load_installed_languages()
    try:
        # å˜—è©¦å–å¾—ç¿»è­¯å™¨
        translation = argostranslate.translate.get_translation_from_codes(from_code, to_code)
        return translation
    
    except Exception:
        print(f"âš ï¸ å°šæœªå®‰è£ {from_code} â†’ {to_code}ï¼Œæ­£åœ¨ä¸‹è¼‰...")
        # å˜—è©¦ä¸‹è¼‰èªè¨€åŒ…
        try:
            argostranslate.package.update_package_index()
            available_packages = argostranslate.package.get_available_packages()
            package_to_install = next(
                filter(
                    lambda x: x.from_code == from_code and x.to_code == to_code, available_packages
                )
            )
            argostranslate.package.install_from_path(package_to_install.download())
            print(f"âœ… æˆåŠŸå®‰è£ {from_code} â†’ {to_code} èªè¨€åŒ…")
            return translation
        
        except Exception as e:
            print("âŒ å®‰è£èªè¨€åŒ…æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š", e)
            return None

ensure_translation_installed("en", "zh")
# ========== GUI ==========
root = tk.Tk()
root.attributes("-topmost", True)
root.overrideredirect(True)
label = tk.Label(root, text="", font=("Arial", 16), bg="black", fg="white", wraplength=400)
label.pack()

# ========== åŠŸèƒ½ ==========
def preprocess_image(img):
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    contrast = cv2.convertScaleAbs(gray, alpha=1.8, beta=0)
    return contrast

def get_changed_regions(current_img):
    global prev_img
    if prev_img is None:
        prev_img = current_img
        return [current_img]

    diff = cv2.absdiff(current_img, prev_img)
    gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    regions = []
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        if w > 10 and h > 10:
            regions.append(current_img[y:y+h, x:x+w])

    prev_img = current_img
    return regions

def translate_text(text):
    from_code, to_code = "en", "zh"
    translation = argostranslate.translate.get_translation_from_codes(from_code, to_code)
    return translation.translate(text)
# ========== æš«åœåŠŸèƒ½ ==========
def toggle_pause():
    global paused
    paused = not paused
    print("ğŸ”´ æš«åœä¸­" if paused else "ğŸŸ¢ å·²æ¢å¾©")

keyboard.add_hotkey('F8', toggle_pause)

def main_loop():
    global prev_text
    with mss.mss() as sct:
        while True:
            if paused:
                label.config(text="ğŸ”´ æš«åœä¸­ (F8 åˆ‡æ›)")
                root.geometry(f"+{bbox['left']}+{bbox['top'] + bbox['height'] + 10}")
                root.update()
                time.sleep(0.3)
                continue

            # æ“·å–ç•«é¢
            raw_img = np.array(sct.grab(bbox))

            # é è™•ç†ï¼ˆè½‰ç°éšï¼‹æé«˜å°æ¯”ï¼‰
            gray = cv2.cvtColor(raw_img, cv2.COLOR_BGR2GRAY)
            contrast = cv2.convertScaleAbs(gray, alpha=1.5, beta=0)

            # OCR è¾¨è­˜
            result = reader.readtext(contrast, detail=0)

            # çµ„æˆä¸€è¡Œæ–‡å­—
            text = " ".join(result).strip()

            # ç¿»è­¯èˆ‡æ›´æ–°é¡¯ç¤º
            if text and text != prev_text:
                translated = translate_text(text)
                label.config(text=translated)
                root.geometry(f"+{bbox['left']}+{bbox['top'] + bbox['height'] + 10}")
                prev_text = text

            root.update()
            time.sleep(0.3)

# ========== å•Ÿå‹•ä¸»åŸ·è¡Œç·’ ==========
threading.Thread(target=main_loop, daemon=True).start()
root.mainloop()
